{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "q-learning-Taxi.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ccc-frankfurt/Practical_ML_SS21/blob/main/week10/q_learning_Taxi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRyizSSW2LDA"
   },
   "source": [
    "This notebook is based on coursera's Practical RL course by National Research University Higher School of Economics, https://www.coursera.org/learn/practical-rl/home/welcome\n",
    "\n",
    "We will make a Q-Learning agent to solve OpenAI Gym's Taxi problem.\n",
    "\n",
    "Q-Learning update equation:\n",
    "\n",
    "\n",
    "*   tabular: $$ Q(s,a) := (1 - \\alpha) \\cdot Q(s,a) + \\alpha \\cdot (r(s,a) + \\gamma \\cdot V(s')) \\\\ = Q(s,a) + \\alpha \\cdot (r(s,a) + \\gamma \\cdot V(s') - Q(s,a))$$\n",
    "\n",
    "For more definitions, see also https://towardsdatascience.com/the-complete-reinforcement-learning-dictionary-e16230b7d24e"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KdVjjTaIlms4"
   },
   "source": [
    "from collections import defaultdict\n",
    "import random, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZQyTVzLTJva"
   },
   "source": [
    "We pick a simple test environment for q-learning: picking up and dropping off customers.\n",
    "\n",
    "Note that for the Taxi environment your reward can be negative, see link for details: https://gym.openai.com/envs/Taxi-v3/"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iRp87KGKu8Ia",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "outputId": "377d7e2a-cc50-4151-a595-058cbbbc360b"
   },
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"Taxi-v3\")\n",
    "env.reset()\n",
    "\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "print('Number of discrete actions:', n_actions, ' - pick up, drop off, up, down, left, right')\n",
    "# observations\n",
    "print(env.observation_space)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "6\n",
      "Discrete(500)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1AruLHu_TYi4"
   },
   "source": [
    "Let's play a game (pick-up and drop off a customer) and see what happens if actions are just randomly sampled."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "l5JI_2WR1cSE",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4803
    },
    "outputId": "d0befd4c-d419-448c-a5df-6dda5d5ac3ec"
   },
   "source": [
    "# render the observations to see how your taxi navigates through the maze\n",
    "s = env.reset()\n",
    "for _ in range(30):\n",
    "    # sample an action\n",
    "    a = env.action_space.sample()\n",
    "    # get the reward and the next state and whether the game has finished\n",
    "    next_s, r, done, _ = env.step(a)\n",
    "    # set the state to the next one\n",
    "    s = next_s\n",
    "    \n",
    "    print('reward: ',r)\n",
    "    env.render()\n",
    "    \n",
    "    if done:\n",
    "        break"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "reward:  -10\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| :\u001B[43m \u001B[0m: : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "reward:  -10\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| :\u001B[43m \u001B[0m: : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "reward:  -1\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001B[43m \u001B[0m: | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "reward:  -1\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001B[43m \u001B[0m: | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "reward:  -1\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001B[43m \u001B[0m: | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "reward:  -1\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001B[43m \u001B[0m: | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "reward:  -1\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| :\u001B[43m \u001B[0m: : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "reward:  -1\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "|\u001B[43m \u001B[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "reward:  -10\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "|\u001B[43m \u001B[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "reward:  -1\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| :\u001B[43m \u001B[0m: : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (East)\n",
      "reward:  -10\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| :\u001B[43m \u001B[0m: : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "reward:  -1\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001B[43m \u001B[0m: | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "reward:  -1\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y|\u001B[43m \u001B[0m: |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "reward:  -10\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y|\u001B[43m \u001B[0m: |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "reward:  -1\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| :\u001B[43m \u001B[0m|B: |\n",
      "+---------+\n",
      "  (East)\n",
      "reward:  -1\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | :\u001B[43m \u001B[0m| : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "reward:  -1\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| :\u001B[43m \u001B[0m|B: |\n",
      "+---------+\n",
      "  (South)\n",
      "reward:  -1\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | :\u001B[43m \u001B[0m| : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "reward:  -10\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | :\u001B[43m \u001B[0m| : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "reward:  -1\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : :\u001B[43m \u001B[0m: : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "reward:  -10\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : :\u001B[43m \u001B[0m: : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "reward:  -1\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | :\u001B[43m \u001B[0m| : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "reward:  -1\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : :\u001B[43m \u001B[0m: : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n",
      "reward:  -10\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : :\u001B[43m \u001B[0m: : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "reward:  -1\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| :\u001B[43m \u001B[0m: : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "reward:  -1\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001B[43m \u001B[0m: | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "reward:  -1\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001B[43m \u001B[0m: | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "reward:  -10\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| |\u001B[43m \u001B[0m: | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "reward:  -1\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y|\u001B[43m \u001B[0m: |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "reward:  -1\n",
      "+---------+\n",
      "|\u001B[35mR\u001B[0m: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| :\u001B[43m \u001B[0m|B: |\n",
      "+---------+\n",
      "  (East)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fprOgg9ZTnd4"
   },
   "source": [
    "Let's now build an agent which will learn a better policy to pick up customers.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "D1nsw7Ex0Kuf"
   },
   "source": [
    "class QLearningAgent:\n",
    "    def __init__(self, alpha, epsilon, discount, get_legal_actions):\n",
    "        \"\"\"\n",
    "        Q-Learning Agent\n",
    "        based on http://ai.berkeley.edu/projects/release/reinforcement/v1/001/docs/qlearningAgents.html\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.get_legal_actions = get_legal_actions\n",
    "        # dictionary of expected rewards for (state,action) pairs\n",
    "        # it is a dictionary of dictionaries, because for every state,\n",
    "        # there could be multiple actions, each of which has qvalue\n",
    "        self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        # learning rate\n",
    "        self.alpha = alpha\n",
    "        # exploration-exploitation trade-off\n",
    "        self.epsilon = epsilon\n",
    "        # gamma - the future reward discount factor\n",
    "        self.discount = discount\n",
    "\n",
    "    def get_qvalue(self, state, action):\n",
    "        \"\"\" Returns Q(state,action) \"\"\"\n",
    "        return self._qvalues[state][action]\n",
    "\n",
    "    def set_qvalue(self,state,action,value):\n",
    "        \"\"\" Sets the Qvalue for [state,action] to the given value \"\"\"\n",
    "        self._qvalues[state][action] = value\n",
    "\n",
    "    def get_value(self, state):\n",
    "        \"\"\"\n",
    "        Compute your agent's estimate of V(s) using current q-values\n",
    "        V(s) = max_over_action Q(state,action) over possible actions.\n",
    "        Note: please take into account that q-values can be negative.\n",
    "        \"\"\"\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "\n",
    "        #If there are no legal actions, return 0.0\n",
    "        if len(possible_actions) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        # go through all possible actions, check the qvalue and return the max\n",
    "        //TODO\n",
    "\n",
    "        return value\n",
    "\n",
    "    def get_best_action(self, state):\n",
    "        \"\"\"\n",
    "        Compute the best action to take in a state (using current q-values). \n",
    "        \"\"\"\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "\n",
    "        #If there are no legal actions, return None\n",
    "        if len(possible_actions) == 0:\n",
    "            return None\n",
    "\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "\n",
    "        #If there are no legal actions, return 0.0\n",
    "        if len(possible_actions) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        # analog to the get_value method, with a different return\n",
    "        //TODO\n",
    "                                                                                  \n",
    "        return best_action\n",
    "        \n",
    "    def get_action(self, state):\n",
    "        \"\"\"\n",
    "        Compute the action to take in the current state, including exploration.  \n",
    "        With probability self.epsilon, we should take a random action.\n",
    "            otherwise - the best policy action.\n",
    "        \n",
    "        Note: To pick randomly from a list, use random.choice(list). \n",
    "              To pick True or False with a given probablity, generate uniform number in [0, 1]\n",
    "              and compare it with your probability.\n",
    "        \"\"\"\n",
    "\n",
    "        # Pick Action\n",
    "        possible_actions = self.get_legal_actions(state)\n",
    "        action = None\n",
    "\n",
    "        # If there are no legal actions, return None\n",
    "        if len(possible_actions) == 0:\n",
    "            return None\n",
    "\n",
    "        //TODO                                                               \n",
    "        \n",
    "        return chosen_action\n",
    "    \n",
    "    def update(self, state, action, reward, next_state, done):\n",
    "        \"\"\"\n",
    "        You should do your Q-Value update here:\n",
    "           Q(s,a) := (1 - alpha) * Q(s,a) + alpha * (r + gamma * V(s'))\n",
    "           \n",
    "        Hint: use get_value method\n",
    "        \"\"\"\n",
    "\n",
    "        //TODO\n",
    "        \n",
    "        self.set_qvalue(state, action, value)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "v0sBB3ZbsSqQ"
   },
   "source": [
    "# initialize a new agent\n",
    "agent = QLearningAgent(alpha=0.5, epsilon=0.25, discount=0.99,\n",
    "                       get_legal_actions = lambda s: range(n_actions))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "l7AysnffDtLF"
   },
   "source": [
    "# update at each train step\n",
    "def play_and_train(env,agent,t_max=10**4):\n",
    "    \"\"\"\n",
    "    This function should \n",
    "    - run a full game, actions given by agent's e-greedy policy\n",
    "    - train agent using agent.update(...) whenever it is possible\n",
    "    - return total reward\n",
    "    \"\"\"\n",
    "    total_reward = 0.0\n",
    "    s = env.reset()\n",
    "    \n",
    "    for t in range(t_max):\n",
    "        # get agent to pick action given state s, get new state and reward, then update your agent\n",
    "        //TODO\n",
    "        \n",
    "        s = next_s\n",
    "        total_reward +=r\n",
    "        if done: break\n",
    "        \n",
    "    return total_reward"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yb5lHa_KZybJ"
   },
   "source": [
    "Let us visualize the reward: play a game and update the agent, dicrease exploration (since the agent has already learned something) and plot the mean reward over the last ones."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jJeVP7SoVguN",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "outputId": "f8a6e5d7-13c9-440d-b41c-055693059cf7"
   },
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "rewards = []\n",
    "for i in range(1000):\n",
    "    rewards.append(play_and_train(env, agent))\n",
    "    # we are making epsilon smaller \n",
    "    agent.epsilon *= 0.99\n",
    "    \n",
    "    if i %100 ==0:\n",
    "        clear_output(True)\n",
    "        print('eps =', agent.epsilon, 'mean reward =', np.mean(rewards[-10:]))\n",
    "        plt.plot(rewards)\n",
    "        plt.show()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "eps = 2.9191091959171894e-05 mean reward = 8.3\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fgw17Mw2Wcya",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2144
    },
    "outputId": "4c980972-3e7a-42b6-ef8e-0e124bc8c222"
   },
   "source": [
    "# render the observations to see how your taxi navigates through the maze\n",
    "s = env.reset()\n",
    "for _ in range(30):\n",
    "    a = agent.get_best_action(s)\n",
    "        \n",
    "    next_s, r, done, _ = env.step(a)\n",
    "    \n",
    "    s = next_s\n",
    "    \n",
    "    env.render()\n",
    "    \n",
    "    if done: break"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001B[43m \u001B[0m| : | : |\n",
      "|Y| : |\u001B[35mB\u001B[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "+---------+\n",
      "|R: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "|\u001B[43m \u001B[0m: : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001B[35mB\u001B[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "+---------+\n",
      "|R: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| :\u001B[43m \u001B[0m: : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001B[35mB\u001B[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "+---------+\n",
      "|R: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : :\u001B[43m \u001B[0m: : |\n",
      "| | : | : |\n",
      "|Y| : |\u001B[35mB\u001B[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "+---------+\n",
      "|R: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : :\u001B[43m \u001B[0m: |\n",
      "| | : | : |\n",
      "|Y| : |\u001B[35mB\u001B[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "+---------+\n",
      "|R: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : :\u001B[43m \u001B[0m|\n",
      "| | : | : |\n",
      "|Y| : |\u001B[35mB\u001B[0m: |\n",
      "+---------+\n",
      "  (East)\n",
      "+---------+\n",
      "|R: | : :\u001B[34;1mG\u001B[0m|\n",
      "| : : : :\u001B[43m \u001B[0m|\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001B[35mB\u001B[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "+---------+\n",
      "|R: | : :\u001B[34;1m\u001B[43mG\u001B[0m\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001B[35mB\u001B[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "+---------+\n",
      "|R: | : :\u001B[42mG\u001B[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001B[35mB\u001B[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : :\u001B[42m_\u001B[0m|\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001B[35mB\u001B[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : :\u001B[42m_\u001B[0m|\n",
      "| | : | : |\n",
      "|Y| : |\u001B[35mB\u001B[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : :\u001B[42m_\u001B[0m: |\n",
      "| | : | : |\n",
      "|Y| : |\u001B[35mB\u001B[0m: |\n",
      "+---------+\n",
      "  (West)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : |\u001B[42m_\u001B[0m: |\n",
      "|Y| : |\u001B[35mB\u001B[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001B[35m\u001B[42mB\u001B[0m\u001B[0m: |\n",
      "+---------+\n",
      "  (South)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001B[35m\u001B[34;1m\u001B[43mB\u001B[0m\u001B[0m\u001B[0m: |\n",
      "+---------+\n",
      "  (Dropoff)\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}
