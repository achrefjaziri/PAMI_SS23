{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "RandomForest_san_francisco_crime.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true,
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3AY5bsgemTi",
    "colab_type": "text"
   },
   "source": [
    "# Random Forests and Titanic dataset\n",
    "\n",
    "Welcome to this week`s session. We will implement Random Forests and use it to predict the survival of titanic passengers.\n",
    "\n",
    "The RandomForest implementation is based on fastai`s machine learning course (see http://course18.fast.ai/lessonsml1/lesson7.html for the lecture and for the code: https://github.com/fastai/fastai/blob/master/courses/ml1/lesson3-rf_foundations.ipynb ). The license for the RandomForest code can be found at: https://github.com/fastai/fastai/blob/master/LICENSE"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-FHU8PmDf2Ja",
    "colab_type": "code",
    "outputId": "31b34e5f-c53f-40ed-c037-c890244db719",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "ExecuteTime": {
     "start_time": "2023-05-03T13:26:26.112116Z",
     "end_time": "2023-05-03T13:26:28.799210Z"
    }
   },
   "source": [
    "!pip install seaborn --upgrade \n",
    "!pip install matplotlib --upgrade\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "import graphviz "
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\program files\\python38\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 186, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"c:\\program files\\python38\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 253, in run\n",
      "    options.use_user_site = decide_user_install(\n",
      "  File \"c:\\program files\\python38\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 604, in decide_user_install\n",
      "    if site_packages_writable(root=root_path, isolated=isolated_mode):\n",
      "  File \"c:\\program files\\python38\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 548, in site_packages_writable\n",
      "    return all(\n",
      "  File \"c:\\program files\\python38\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 549, in <genexpr>\n",
      "    test_writable_dir(d) for d in set(get_lib_location_guesses(**kwargs))\n",
      "  File \"c:\\program files\\python38\\lib\\site-packages\\pip\\_internal\\utils\\filesystem.py\", line 140, in test_writable_dir\n",
      "    return _test_writable_dir_win(path)\n",
      "  File \"c:\\program files\\python38\\lib\\site-packages\\pip\\_internal\\utils\\filesystem.py\", line 153, in _test_writable_dir_win\n",
      "    fd = os.open(file, os.O_RDWR | os.O_CREAT | os.O_EXCL)\n",
      "PermissionError: [Errno 13] Permission denied: 'c:\\\\program files\\\\python38\\\\Lib\\\\site-packages\\\\accesstest_deleteme_fishfingers_custard_vwkff0'\n",
      "WARNING: You are using pip version 20.0.2; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\program files\\python38\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 186, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"c:\\program files\\python38\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 253, in run\n",
      "    options.use_user_site = decide_user_install(\n",
      "  File \"c:\\program files\\python38\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 604, in decide_user_install\n",
      "    if site_packages_writable(root=root_path, isolated=isolated_mode):\n",
      "  File \"c:\\program files\\python38\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 548, in site_packages_writable\n",
      "    return all(\n",
      "  File \"c:\\program files\\python38\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 549, in <genexpr>\n",
      "    test_writable_dir(d) for d in set(get_lib_location_guesses(**kwargs))\n",
      "  File \"c:\\program files\\python38\\lib\\site-packages\\pip\\_internal\\utils\\filesystem.py\", line 140, in test_writable_dir\n",
      "    return _test_writable_dir_win(path)\n",
      "  File \"c:\\program files\\python38\\lib\\site-packages\\pip\\_internal\\utils\\filesystem.py\", line 153, in _test_writable_dir_win\n",
      "    fd = os.open(file, os.O_RDWR | os.O_CREAT | os.O_EXCL)\n",
      "PermissionError: [Errno 13] Permission denied: 'c:\\\\program files\\\\python38\\\\Lib\\\\site-packages\\\\accesstest_deleteme_fishfingers_custard_q8xe24'\n",
      "WARNING: You are using pip version 20.0.2; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\program files\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UIuitMDIYkn5",
    "colab_type": "text"
   },
   "source": [
    "## Revisiting the Titanic dataset \n",
    "Loading the Titanic dataset which you are already acquainted with."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LW4ffTwmburW",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "start_time": "2023-05-03T13:26:28.789223Z",
     "end_time": "2023-05-03T13:26:28.905209Z"
    }
   },
   "source": [
    "sns.set()\n",
    "titanic = sns.load_dataset(\"titanic\")\n",
    "titanic = titanic.dropna(subset=[\"embarked\", \"embark_town\"])\n",
    "print(titanic.describe())"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         survived      pclass         age       sibsp       parch        fare\n",
      "count  889.000000  889.000000  712.000000  889.000000  889.000000  889.000000\n",
      "mean     0.382452    2.311586   29.642093    0.524184    0.382452   32.096681\n",
      "std      0.486260    0.834700   14.492933    1.103705    0.806761   49.697504\n",
      "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
      "25%      0.000000    2.000000   20.000000    0.000000    0.000000    7.895800\n",
      "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
      "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
      "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xExBRTYFcaTy",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "start_time": "2023-05-03T13:26:28.839213Z",
     "end_time": "2023-05-03T13:26:28.953210Z"
    }
   },
   "source": [
    "sex = pd.get_dummies(titanic[\"sex\"], drop_first=True)\n",
    "fare = titanic[\"fare\"]\n",
    "parch = titanic[\"parch\"]\n",
    "pclass = titanic[\"pclass\"]\n",
    "sibsp = titanic[\"sibsp\"]\n",
    "\n",
    "x = pd.concat([sex, fare, parch, pclass, sibsp], axis=1)\n",
    "y = titanic[\"survived\"].values\n",
    "labels = ['not survived', 'survived']"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrpU_l0BvhQ1",
    "colab_type": "text"
   },
   "source": [
    "In contrast to some other exercises where we converted our tabular data to Numpy matrices, this is not necessary here. Instead we can use Pandas' data frame directly and index the needed data with the \"iloc\" function. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Xi59pgXdh5W1",
    "colab_type": "code",
    "outputId": "160529f7-4fe9-47e7-8159-6237c22337db",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "ExecuteTime": {
     "start_time": "2023-05-03T13:26:28.851221Z",
     "end_time": "2023-05-03T13:26:28.965213Z"
    }
   },
   "source": [
    "perm = np.random.permutation(len(x))\n",
    "\n",
    "split = 0.8\n",
    "\n",
    "x_train, x_test = x.iloc[perm[:int(split*len(x))]], x.iloc[perm[int(split*len(x)):]]\n",
    "y_train, y_test = y[perm[:int(split*len(y))]], y[perm[int(split*len(y)):]]\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(711, 5) (178, 5) (711,) (178,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CqnjQEKxp5u",
    "colab_type": "text"
   },
   "source": [
    "Define a function to compute the accuracy of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uPIwQYqNX2FS",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "start_time": "2023-05-03T13:26:28.860212Z",
     "end_time": "2023-05-03T13:26:28.966212Z"
    }
   },
   "source": [
    "# this accuracy calculation will work only for 2 classes (!)\n",
    "def accuracy(pred, y_target):\n",
    "    threshold = 0.5\n",
    "    y_target = y_target.squeeze()\n",
    "    pred=pred.squeeze()\n",
    "    \n",
    "    # where boolean prediction mask and target match, there will be a 1, else 0\n",
    "    return ((pred>=threshold)*y_target+(pred < threshold)*(1-y_target)).sum()/float(len(y_target))"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9J-s9nUlYhuw",
    "colab_type": "text"
   },
   "source": [
    "## Introduction to sklearn`s **RandomForestClassifier** and **RandomForestRegressor**\n",
    "First, we will classify, which Titanic passengers survived, using the RandomForestClassifier. Then, RandomForestRegressor will be used for the same task to exemplify that the **splitting metric**, as well as **leaf values** (classes vs. numbers) differs, but in principle the way the tree is grown stays the same."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hr6oVikmeApL",
    "colab_type": "code",
    "outputId": "97352a86-c98c-4f38-fd75-e0e7ad7dca53",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "ExecuteTime": {
     "start_time": "2023-05-03T13:26:28.881211Z",
     "end_time": "2023-05-03T13:26:28.973212Z"
    }
   },
   "source": [
    "# define the RandomForestClassifier and fit the data (build 1 tree with max depth 2 and set the bootstrap parameter to False)\n",
    "# when bootstrap is set to false, all the data are fed to every classifier\n",
    "m = RandomForestClassifier(n_estimators=1, max_depth=2, bootstrap=False)\n",
    "m.fit(x_train, y_train)"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=False, max_depth=2, n_estimators=1)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kdSQNWmqeIDH",
    "colab_type": "code",
    "outputId": "70a881df-77a6-4155-ed29-bed847e8314c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "ExecuteTime": {
     "start_time": "2023-05-03T13:26:28.915212Z",
     "end_time": "2023-05-03T13:26:28.974216Z"
    }
   },
   "source": [
    "# predict the results for your train and test data\n",
    "preds_train = m.predict(x_train)\n",
    "preds_test = m.predict(x_test)\n",
    "\n",
    "# calculate the accuracy\n",
    "acc_train = accuracy(preds_train, y_train)\n",
    "acc_test = accuracy(preds_test, y_test)\n",
    "\n",
    "# print the results\n",
    "print('train_acc: {0:4f}, test_acc: {1:4f}'.format(acc_train, acc_test))"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc: 0.791842, test_acc: 0.764045\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKKQP3ST2LCP",
    "colab_type": "text"
   },
   "source": [
    "**Graphviz ** is an open source graph visualization software: \n",
    "https://www.graphviz.org/, \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XPjHuGHxeSAF",
    "colab_type": "code",
    "outputId": "94370c07-3794-4624-e4b8-e85ac3cb5880",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "ExecuteTime": {
     "start_time": "2023-05-03T13:26:31.510931Z",
     "end_time": "2023-05-03T13:26:31.582933Z"
    }
   },
   "source": [
    "# visualize the fitted tree to your train data\n",
    "dot_data = tree.export_graphviz(m.estimators_[0],\n",
    "                                out_file=None, \n",
    "                                feature_names=x_train.columns,  \n",
    "                                class_names=labels,\n",
    "                                filled=True,\n",
    "                                rounded=True,  \n",
    "                                special_characters=True)  \n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "t = m.estimators_[0].tree_\n",
    "\n",
    "n_samples = len(y_train)\n",
    "\n",
    "# the first zero indicates the first node, \n",
    "# the second can be ignored, the third one is the non-survived/survived value\n",
    "n_samples_ns = t.value[0][0][0] # number of not survived after first split\n",
    "n_samples_s = t.value[0][0][1] # number of survived after first split\n",
    "\n",
    "n_samples_left_ns = t.value[1][0][0]\n",
    "n_samples_left_s = t.value[1][0][1]\n",
    "\n",
    "n_samples_left = n_samples_left_ns + n_samples_left_s\n",
    "\n",
    "# compare the values with the graph below\n",
    "print(n_samples,n_samples_ns,n_samples_s,n_samples_left,n_samples_left_ns,n_samples_left_s)\n",
    "\n",
    "# compute the gini impurity for the root node and its left child\n",
    "gini_root = 1. - (n_samples_ns/n_samples)**2 - (n_samples_s/n_samples)**2 #TODO\n",
    "gini_left = 1. - (n_samples_left_ns/n_samples_left)**2 - (n_samples_left_s/n_samples_left)**2 #TODO\n",
    "\n",
    "print('gini_root: {0:2f}, gini_left: {1:3f}'.format(gini_root, gini_left))\n",
    "\n",
    "graph"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711 435.0 276.0 290.0 229.0 61.0\n",
      "gini_root: 0.474995, gini_left: 0.332200\n"
     ]
    },
    {
     "data": {
      "text/plain": "<graphviz.files.Source at 0x21d8026b190>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Generated by graphviz version 8.0.3 (20230416.2022)\r\n -->\r\n<!-- Title: Tree Pages: 1 -->\r\n<svg width=\"588pt\" height=\"314pt\"\r\n viewBox=\"0.00 0.00 587.50 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\r\n<title>Tree</title>\r\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-310 583.5,-310 583.5,4 -4,4\"/>\r\n<!-- 0 -->\r\n<g id=\"node1\" class=\"node\">\r\n<title>0</title>\r\n<path fill=\"#f5d1b7\" stroke=\"black\" d=\"M341.5,-306C341.5,-306 224.5,-306 224.5,-306 218.5,-306 212.5,-300 212.5,-294 212.5,-294 212.5,-235 212.5,-235 212.5,-229 218.5,-223 224.5,-223 224.5,-223 341.5,-223 341.5,-223 347.5,-223 353.5,-229 353.5,-235 353.5,-235 353.5,-294 353.5,-294 353.5,-300 347.5,-306 341.5,-306\"/>\r\n<text text-anchor=\"start\" x=\"240.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">fare ≤ 10.825</text>\r\n<text text-anchor=\"start\" x=\"245.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.475</text>\r\n<text text-anchor=\"start\" x=\"235.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 711</text>\r\n<text text-anchor=\"start\" x=\"226\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [435, 276]</text>\r\n<text text-anchor=\"start\" x=\"220.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = not survived</text>\r\n</g>\r\n<!-- 1 -->\r\n<g id=\"node2\" class=\"node\">\r\n<title>1</title>\r\n<path fill=\"#eca36e\" stroke=\"black\" d=\"M264.5,-187C264.5,-187 147.5,-187 147.5,-187 141.5,-187 135.5,-181 135.5,-175 135.5,-175 135.5,-116 135.5,-116 135.5,-110 141.5,-104 147.5,-104 147.5,-104 264.5,-104 264.5,-104 270.5,-104 276.5,-110 276.5,-116 276.5,-116 276.5,-175 276.5,-175 276.5,-181 270.5,-187 264.5,-187\"/>\r\n<text text-anchor=\"start\" x=\"172.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">male ≤ 0.5</text>\r\n<text text-anchor=\"start\" x=\"168.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.332</text>\r\n<text text-anchor=\"start\" x=\"158.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 290</text>\r\n<text text-anchor=\"start\" x=\"153\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [229, 61]</text>\r\n<text text-anchor=\"start\" x=\"143.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = not survived</text>\r\n</g>\r\n<!-- 0&#45;&gt;1 -->\r\n<g id=\"edge1\" class=\"edge\">\r\n<title>0&#45;&gt;1</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M256.07,-222.58C250.47,-214.07 244.51,-205.01 238.73,-196.23\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"241.21,-194.63 232.79,-188.2 235.36,-198.48 241.21,-194.63\"/>\r\n<text text-anchor=\"middle\" x=\"227.74\" y=\"-207.99\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n</g>\r\n<!-- 4 -->\r\n<g id=\"node5\" class=\"node\">\r\n<title>4</title>\r\n<path fill=\"#f7fbfe\" stroke=\"black\" d=\"M413,-187C413,-187 307,-187 307,-187 301,-187 295,-181 295,-175 295,-175 295,-116 295,-116 295,-110 301,-104 307,-104 307,-104 413,-104 413,-104 419,-104 425,-110 425,-116 425,-116 425,-175 425,-175 425,-181 419,-187 413,-187\"/>\r\n<text text-anchor=\"start\" x=\"326.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">male ≤ 0.5</text>\r\n<text text-anchor=\"start\" x=\"331\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\r\n<text text-anchor=\"start\" x=\"312.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 421</text>\r\n<text text-anchor=\"start\" x=\"303\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [206, 215]</text>\r\n<text text-anchor=\"start\" x=\"309\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = survived</text>\r\n</g>\r\n<!-- 0&#45;&gt;4 -->\r\n<g id=\"edge4\" class=\"edge\">\r\n<title>0&#45;&gt;4</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M309.93,-222.58C315.53,-214.07 321.49,-205.01 327.27,-196.23\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"330.64,-198.48 333.21,-188.2 324.79,-194.63 330.64,-198.48\"/>\r\n<text text-anchor=\"middle\" x=\"338.26\" y=\"-207.99\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n</g>\r\n<!-- 2 -->\r\n<g id=\"node3\" class=\"node\">\r\n<title>2</title>\r\n<path fill=\"#b4daf5\" stroke=\"black\" d=\"M106,-68C106,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 106,0 106,0 112,0 118,-6 118,-12 118,-12 118,-56 118,-56 118,-62 112,-68 106,-68\"/>\r\n<text text-anchor=\"start\" x=\"21.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.473</text>\r\n<text text-anchor=\"start\" x=\"15.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 60</text>\r\n<text text-anchor=\"start\" x=\"10.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [23, 37]</text>\r\n<text text-anchor=\"start\" x=\"8\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = survived</text>\r\n</g>\r\n<!-- 1&#45;&gt;2 -->\r\n<g id=\"edge2\" class=\"edge\">\r\n<title>1&#45;&gt;2</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M151.26,-103.73C138.53,-94.24 124.99,-84.16 112.32,-74.72\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"114.81,-71.47 104.7,-68.3 110.63,-77.08 114.81,-71.47\"/>\r\n</g>\r\n<!-- 3 -->\r\n<g id=\"node4\" class=\"node\">\r\n<title>3</title>\r\n<path fill=\"#e89050\" stroke=\"black\" d=\"M265.5,-68C265.5,-68 148.5,-68 148.5,-68 142.5,-68 136.5,-62 136.5,-56 136.5,-56 136.5,-12 136.5,-12 136.5,-6 142.5,0 148.5,0 148.5,0 265.5,0 265.5,0 271.5,0 277.5,-6 277.5,-12 277.5,-12 277.5,-56 277.5,-56 277.5,-62 271.5,-68 265.5,-68\"/>\r\n<text text-anchor=\"start\" x=\"169.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.187</text>\r\n<text text-anchor=\"start\" x=\"159.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 230</text>\r\n<text text-anchor=\"start\" x=\"154\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [206, 24]</text>\r\n<text text-anchor=\"start\" x=\"144.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = not survived</text>\r\n</g>\r\n<!-- 1&#45;&gt;3 -->\r\n<g id=\"edge3\" class=\"edge\">\r\n<title>1&#45;&gt;3</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M206.37,-103.73C206.45,-95.7 206.52,-87.24 206.6,-79.11\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"210.1,-79.33 206.7,-69.3 203.1,-79.27 210.1,-79.33\"/>\r\n</g>\r\n<!-- 5 -->\r\n<g id=\"node6\" class=\"node\">\r\n<title>5</title>\r\n<path fill=\"#6eb7ec\" stroke=\"black\" d=\"M408,-68C408,-68 310,-68 310,-68 304,-68 298,-62 298,-56 298,-56 298,-12 298,-12 298,-6 304,0 310,0 310,0 408,0 408,0 414,0 420,-6 420,-12 420,-12 420,-56 420,-56 420,-62 414,-68 408,-68\"/>\r\n<text text-anchor=\"start\" x=\"321.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.334</text>\r\n<text text-anchor=\"start\" x=\"311.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 198</text>\r\n<text text-anchor=\"start\" x=\"306\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [42, 156]</text>\r\n<text text-anchor=\"start\" x=\"308\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = survived</text>\r\n</g>\r\n<!-- 4&#45;&gt;5 -->\r\n<g id=\"edge5\" class=\"edge\">\r\n<title>4&#45;&gt;5</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M359.63,-103.73C359.55,-95.7 359.48,-87.24 359.4,-79.11\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"362.9,-79.27 359.3,-69.3 355.9,-79.33 362.9,-79.27\"/>\r\n</g>\r\n<!-- 6 -->\r\n<g id=\"node7\" class=\"node\">\r\n<title>6</title>\r\n<path fill=\"#eeae80\" stroke=\"black\" d=\"M567.5,-68C567.5,-68 450.5,-68 450.5,-68 444.5,-68 438.5,-62 438.5,-56 438.5,-56 438.5,-12 438.5,-12 438.5,-6 444.5,0 450.5,0 450.5,0 567.5,0 567.5,0 573.5,0 579.5,-6 579.5,-12 579.5,-12 579.5,-56 579.5,-56 579.5,-62 573.5,-68 567.5,-68\"/>\r\n<text text-anchor=\"start\" x=\"471.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.389</text>\r\n<text text-anchor=\"start\" x=\"461.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 223</text>\r\n<text text-anchor=\"start\" x=\"456\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [164, 59]</text>\r\n<text text-anchor=\"start\" x=\"446.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = not survived</text>\r\n</g>\r\n<!-- 4&#45;&gt;6 -->\r\n<g id=\"edge6\" class=\"edge\">\r\n<title>4&#45;&gt;6</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M415.48,-103.73C428.39,-94.24 442.11,-84.16 454.96,-74.72\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"456.7,-77.04 462.69,-68.3 452.56,-71.4 456.7,-77.04\"/>\r\n</g>\r\n</g>\r\n</svg>\r\n"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptYrR3l0haDi",
    "colab_type": "text"
   },
   "source": [
    "Let us change the splitting criterion from **Gini** to **Information Gain**."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JIKo65KAhXtO",
    "colab_type": "code",
    "outputId": "6e4e9321-7398-4b6d-b822-0468a191c2bd",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 491
    },
    "ExecuteTime": {
     "start_time": "2023-05-03T13:27:12.755289Z",
     "end_time": "2023-05-03T13:27:12.821302Z"
    }
   },
   "source": [
    "# define the RandomForestClassifier with entropy as the splitting criterion, 1 tree, max_depth=2 and bootstrap=False\n",
    "# and fit the data\n",
    "m = RandomForestClassifier(n_estimators=1, criterion=\"entropy\", max_depth=2, bootstrap=False)\n",
    "m.fit(x_train, y_train)\n",
    "\n",
    "# predict the results for your train and test data\n",
    "preds_train = m.predict(x_train)\n",
    "preds_test = m.predict(x_test)\n",
    "\n",
    "# calculate the accuracy\n",
    "acc_train = accuracy(preds_train, y_train)\n",
    "acc_test = accuracy(preds_test, y_test)\n",
    "\n",
    "# print the results\n",
    "print('train_acc: {0:4f}, test_acc: {1:4f}'.format(acc_train, acc_test))\n",
    "\n",
    "# prepare the variables for the entropy gain calculation\n",
    "t = m.estimators_[0].tree_\n",
    "n_samples = float(len(y_train))\n",
    "\n",
    "n_samples_ns = t.value[0][0][0] # number of not survived before first split\n",
    "n_samples_s = t.value[0][0][1] # number of survived before first split\n",
    "\n",
    "n_samples_lns = t.value[1][0][0] # number of not survived after first split for the first node\n",
    "n_samples_ls = t.value[1][0][1]\n",
    "\n",
    "n_samples_left = float(n_samples_lns + n_samples_ls)\n",
    "\n",
    "# to get the root right nodes directly, use children_right\n",
    "n_samples_rns = t.value[t.children_right][0][0][0]\n",
    "n_samples_rs = t.value[t.children_right][0][0][1]\n",
    "\n",
    "n_samples_right = float(n_samples_rns + n_samples_rs)\n",
    "\n",
    "# calculate the entropy gain\n",
    "\n",
    "entropy_root = //TODO\n",
    "\n",
    "entropy_left = //TODO\n",
    "entropy_right = //TODO\n",
    "\n",
    "print('root_entropy:{0:4f}, left_entropy:{1:4f}, right_entropy:{2:4f}'.format(entropy_root, entropy_left, entropy_right))\n",
    "\n",
    "gain = entropy_root - (n_samples_left/n_samples)*entropy_left - (n_samples_right/n_samples)*entropy_right\n",
    "intrinsic_information = -(n_samples_left/n_samples)*np.log2(n_samples_left/n_samples)-(n_samples_right/n_samples)*np.log2(n_samples_right/n_samples)\n",
    "gain_ratio = gain/intrinsic_information\n",
    "\n",
    "print('gain: {0:2f}, intrinsic_information: {1:3f}, gain_ratio: {2:3f}'.format(gain, intrinsic_information, gain_ratio))\n",
    "\n",
    "# visualize the fitted tree to your train data\n",
    "dot_data = tree.export_graphviz(m.estimators_[0], out_file=None, \n",
    "                         feature_names=x_train.columns,  \n",
    "                         class_names=labels,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc: 0.679325, test_acc: 0.646067\n",
      "root_entropy:0.963619, left_entropy:0.991076, right_entropy:0.808192\n",
      "gain: 0.072087, intrinsic_information: 0.994329, gain_ratio: 0.072498\n"
     ]
    },
    {
     "data": {
      "text/plain": "<graphviz.files.Source at 0x21d80277eb0>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Generated by graphviz version 8.0.3 (20230416.2022)\r\n -->\r\n<!-- Title: Tree Pages: 1 -->\r\n<svg width=\"590pt\" height=\"314pt\"\r\n viewBox=\"0.00 0.00 590.00 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\r\n<title>Tree</title>\r\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-310 586,-310 586,4 -4,4\"/>\r\n<!-- 0 -->\r\n<g id=\"node1\" class=\"node\">\r\n<title>0</title>\r\n<path fill=\"#f5d1b7\" stroke=\"black\" d=\"M349,-306C349,-306 232,-306 232,-306 226,-306 220,-300 220,-294 220,-294 220,-235 220,-235 220,-229 226,-223 232,-223 232,-223 349,-223 349,-223 355,-223 361,-229 361,-235 361,-235 361,-294 361,-294 361,-300 355,-306 349,-306\"/>\r\n<text text-anchor=\"start\" x=\"252\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">pclass ≤ 2.5</text>\r\n<text text-anchor=\"start\" x=\"240.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.964</text>\r\n<text text-anchor=\"start\" x=\"243\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 711</text>\r\n<text text-anchor=\"start\" x=\"233.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [435, 276]</text>\r\n<text text-anchor=\"start\" x=\"228\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = not survived</text>\r\n</g>\r\n<!-- 1 -->\r\n<g id=\"node2\" class=\"node\">\r\n<title>1</title>\r\n<path fill=\"#d7ebfa\" stroke=\"black\" d=\"M266.5,-187C266.5,-187 160.5,-187 160.5,-187 154.5,-187 148.5,-181 148.5,-175 148.5,-175 148.5,-116 148.5,-116 148.5,-110 154.5,-104 160.5,-104 160.5,-104 266.5,-104 266.5,-104 272.5,-104 278.5,-110 278.5,-116 278.5,-116 278.5,-175 278.5,-175 278.5,-181 272.5,-187 266.5,-187\"/>\r\n<text text-anchor=\"start\" x=\"178.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">sibsp ≤ 0.5</text>\r\n<text text-anchor=\"start\" x=\"163.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.991</text>\r\n<text text-anchor=\"start\" x=\"166\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 324</text>\r\n<text text-anchor=\"start\" x=\"156.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [144, 180]</text>\r\n<text text-anchor=\"start\" x=\"162.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = survived</text>\r\n</g>\r\n<!-- 0&#45;&gt;1 -->\r\n<g id=\"edge1\" class=\"edge\">\r\n<title>0&#45;&gt;1</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M263.57,-222.58C257.97,-214.07 252.01,-205.01 246.23,-196.23\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"248.71,-194.63 240.29,-188.2 242.86,-198.48 248.71,-194.63\"/>\r\n<text text-anchor=\"middle\" x=\"235.24\" y=\"-207.99\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n</g>\r\n<!-- 4 -->\r\n<g id=\"node5\" class=\"node\">\r\n<title>4</title>\r\n<path fill=\"#eeab7a\" stroke=\"black\" d=\"M426,-187C426,-187 309,-187 309,-187 303,-187 297,-181 297,-175 297,-175 297,-116 297,-116 297,-110 303,-104 309,-104 309,-104 426,-104 426,-104 432,-104 438,-110 438,-116 438,-116 438,-175 438,-175 438,-181 432,-187 426,-187\"/>\r\n<text text-anchor=\"start\" x=\"334\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">male ≤ 0.5</text>\r\n<text text-anchor=\"start\" x=\"317.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.808</text>\r\n<text text-anchor=\"start\" x=\"320\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 387</text>\r\n<text text-anchor=\"start\" x=\"314.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [291, 96]</text>\r\n<text text-anchor=\"start\" x=\"305\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = not survived</text>\r\n</g>\r\n<!-- 0&#45;&gt;4 -->\r\n<g id=\"edge4\" class=\"edge\">\r\n<title>0&#45;&gt;4</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M317.43,-222.58C323.03,-214.07 328.99,-205.01 334.77,-196.23\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"338.14,-198.48 340.71,-188.2 332.29,-194.63 338.14,-198.48\"/>\r\n<text text-anchor=\"middle\" x=\"345.76\" y=\"-207.99\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n</g>\r\n<!-- 2 -->\r\n<g id=\"node3\" class=\"node\">\r\n<title>2</title>\r\n<path fill=\"#fdf6f0\" stroke=\"black\" d=\"M129,-68C129,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 129,0 129,0 135,0 141,-6 141,-12 141,-12 141,-56 141,-56 141,-62 135,-68 129,-68\"/>\r\n<text text-anchor=\"start\" x=\"20.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.999</text>\r\n<text text-anchor=\"start\" x=\"23\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 210</text>\r\n<text text-anchor=\"start\" x=\"13.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [109, 101]</text>\r\n<text text-anchor=\"start\" x=\"8\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = not survived</text>\r\n</g>\r\n<!-- 1&#45;&gt;2 -->\r\n<g id=\"edge2\" class=\"edge\">\r\n<title>1&#45;&gt;2</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M160.25,-103.73C147.86,-94.24 134.69,-84.16 122.37,-74.72\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"125.05,-71.6 114.99,-68.3 120.8,-77.16 125.05,-71.6\"/>\r\n</g>\r\n<!-- 3 -->\r\n<g id=\"node4\" class=\"node\">\r\n<title>3</title>\r\n<path fill=\"#91c8f1\" stroke=\"black\" d=\"M265.5,-68C265.5,-68 171.5,-68 171.5,-68 165.5,-68 159.5,-62 159.5,-56 159.5,-56 159.5,-12 159.5,-12 159.5,-6 165.5,0 171.5,0 171.5,0 265.5,0 265.5,0 271.5,0 277.5,-6 277.5,-12 277.5,-12 277.5,-56 277.5,-56 277.5,-62 271.5,-68 265.5,-68\"/>\r\n<text text-anchor=\"start\" x=\"172.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.89</text>\r\n<text text-anchor=\"start\" x=\"171\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 114</text>\r\n<text text-anchor=\"start\" x=\"170\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [35, 79]</text>\r\n<text text-anchor=\"start\" x=\"167.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = survived</text>\r\n</g>\r\n<!-- 1&#45;&gt;3 -->\r\n<g id=\"edge3\" class=\"edge\">\r\n<title>1&#45;&gt;3</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M215.36,-103.73C215.73,-95.7 216.11,-87.24 216.49,-79.11\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"220.02,-79.45 216.98,-69.3 213.03,-79.13 220.02,-79.45\"/>\r\n</g>\r\n<!-- 5 -->\r\n<g id=\"node6\" class=\"node\">\r\n<title>5</title>\r\n<path fill=\"#f2f9fd\" stroke=\"black\" d=\"M410.5,-68C410.5,-68 316.5,-68 316.5,-68 310.5,-68 304.5,-62 304.5,-56 304.5,-56 304.5,-12 304.5,-12 304.5,-6 310.5,0 316.5,0 316.5,0 410.5,0 410.5,0 416.5,0 422.5,-6 422.5,-12 422.5,-12 422.5,-56 422.5,-56 422.5,-62 416.5,-68 410.5,-68\"/>\r\n<text text-anchor=\"start\" x=\"313.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.999</text>\r\n<text text-anchor=\"start\" x=\"316\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 120</text>\r\n<text text-anchor=\"start\" x=\"315\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [58, 62]</text>\r\n<text text-anchor=\"start\" x=\"312.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = survived</text>\r\n</g>\r\n<!-- 4&#45;&gt;5 -->\r\n<g id=\"edge5\" class=\"edge\">\r\n<title>4&#45;&gt;5</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M366.01,-103.73C365.72,-95.7 365.41,-87.24 365.11,-79.11\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"368.58,-79.17 364.72,-69.3 361.58,-79.42 368.58,-79.17\"/>\r\n</g>\r\n<!-- 6 -->\r\n<g id=\"node7\" class=\"node\">\r\n<title>6</title>\r\n<path fill=\"#e99356\" stroke=\"black\" d=\"M570,-68C570,-68 453,-68 453,-68 447,-68 441,-62 441,-56 441,-56 441,-12 441,-12 441,-6 447,0 453,0 453,0 570,0 570,0 576,0 582,-6 582,-12 582,-12 582,-56 582,-56 582,-62 576,-68 570,-68\"/>\r\n<text text-anchor=\"start\" x=\"465.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.55</text>\r\n<text text-anchor=\"start\" x=\"464\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 267</text>\r\n<text text-anchor=\"start\" x=\"458.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [233, 34]</text>\r\n<text text-anchor=\"start\" x=\"449\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = not survived</text>\r\n</g>\r\n<!-- 4&#45;&gt;6 -->\r\n<g id=\"edge6\" class=\"edge\">\r\n<title>4&#45;&gt;6</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M421.12,-103.73C433.59,-94.24 446.86,-84.16 459.27,-74.72\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"460.87,-77.14 466.71,-68.3 456.63,-71.57 460.87,-77.14\"/>\r\n</g>\r\n</g>\r\n</svg>\r\n"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WK4i9pUWdVNA",
    "colab_type": "text"
   },
   "source": [
    "Let us repeat the same process we went through for the **RandomForestClassifier**, for the **RandomForestRegressor**: \n",
    "\n",
    "1. define the regressor\n",
    "2. fit the data\n",
    "3. calculate the accuracy\n",
    "4. visualize the tree graph for the first tree\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "h6QgWsTER8pV",
    "colab_type": "code",
    "outputId": "3d22f14b-2164-4c98-d02a-d45f5eca514c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "ExecuteTime": {
     "start_time": "2023-05-03T13:27:25.445037Z",
     "end_time": "2023-05-03T13:27:25.471033Z"
    }
   },
   "source": [
    "# define the RandomForestRegressor and fit the data\n",
    "m = RandomForestRegressor(n_estimators=1, max_depth=2, bootstrap=False)\n",
    "m.fit(x_train, y_train)"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestRegressor(bootstrap=False, max_depth=2, n_estimators=1)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "chQdahl2eNIY",
    "colab_type": "code",
    "outputId": "31048ea0-2ff8-4e5e-c143-e943d6f967f0",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "ExecuteTime": {
     "start_time": "2023-05-03T13:27:28.015119Z",
     "end_time": "2023-05-03T13:27:28.037130Z"
    }
   },
   "source": [
    "# predict the results for your train and test data\n",
    "preds_train = m.predict(x_train)\n",
    "preds_test = m.predict(x_test)\n",
    "\n",
    "# calculate the accuracy\n",
    "\n",
    "acc_train = accuracy(preds_train, y_train)\n",
    "acc_test = accuracy(preds_test, y_test)\n",
    "\n",
    "# print the results\n",
    "print('train_acc: {0:4f}, test_acc: {1:4f}'.format(acc_train, acc_test))"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc: 0.791842, test_acc: 0.764045\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5F6u1n3AV5vK",
    "colab_type": "code",
    "outputId": "37292ce8-6301-434e-b0f0-64292bd23f81",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "ExecuteTime": {
     "start_time": "2023-05-03T13:27:29.728104Z",
     "end_time": "2023-05-03T13:27:29.792098Z"
    }
   },
   "source": [
    "# visualize the fitted tree to your train data\n",
    "dot_data = tree.export_graphviz(m.estimators_[0], out_file=None, \n",
    "                         feature_names=x_train.columns,  \n",
    "                         class_names=labels,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<graphviz.files.Source at 0x21d8026b970>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Generated by graphviz version 8.0.3 (20230416.2022)\r\n -->\r\n<!-- Title: Tree Pages: 1 -->\r\n<svg width=\"500pt\" height=\"269pt\"\r\n viewBox=\"0.00 0.00 500.00 269.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 265)\">\r\n<title>Tree</title>\r\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-265 496,-265 496,4 -4,4\"/>\r\n<!-- 0 -->\r\n<g id=\"node1\" class=\"node\">\r\n<title>0</title>\r\n<path fill=\"#f7d7c1\" stroke=\"black\" d=\"M291,-261C291,-261 204,-261 204,-261 198,-261 192,-255 192,-249 192,-249 192,-205 192,-205 192,-199 198,-193 204,-193 204,-193 291,-193 291,-193 297,-193 303,-199 303,-205 303,-205 303,-249 303,-249 303,-255 297,-261 291,-261\"/>\r\n<text text-anchor=\"start\" x=\"214\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">male ≤ 0.5</text>\r\n<text text-anchor=\"start\" x=\"207\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 0.237</text>\r\n<text text-anchor=\"start\" x=\"200\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 711</text>\r\n<text text-anchor=\"start\" x=\"204.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.388</text>\r\n</g>\r\n<!-- 1 -->\r\n<g id=\"node2\" class=\"node\">\r\n<title>1</title>\r\n<path fill=\"#eba06a\" stroke=\"black\" d=\"M227,-157C227,-157 140,-157 140,-157 134,-157 128,-151 128,-145 128,-145 128,-101 128,-101 128,-95 134,-89 140,-89 140,-89 227,-89 227,-89 233,-89 239,-95 239,-101 239,-101 239,-145 239,-145 239,-151 233,-157 227,-157\"/>\r\n<text text-anchor=\"start\" x=\"145\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">pclass ≤ 2.5</text>\r\n<text text-anchor=\"start\" x=\"143\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 0.188</text>\r\n<text text-anchor=\"start\" x=\"136\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 258</text>\r\n<text text-anchor=\"start\" x=\"140.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.748</text>\r\n</g>\r\n<!-- 0&#45;&gt;1 -->\r\n<g id=\"edge1\" class=\"edge\">\r\n<title>0&#45;&gt;1</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M226.54,-192.6C221.35,-184.32 215.71,-175.34 210.28,-166.69\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"212.78,-165.08 204.5,-158.47 206.85,-168.8 212.78,-165.08\"/>\r\n<text text-anchor=\"middle\" x=\"198.92\" y=\"-178.14\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n</g>\r\n<!-- 4 -->\r\n<g id=\"node5\" class=\"node\">\r\n<title>4</title>\r\n<path fill=\"#fdf7f2\" stroke=\"black\" d=\"M356,-157C356,-157 269,-157 269,-157 263,-157 257,-151 257,-145 257,-145 257,-101 257,-101 257,-95 263,-89 269,-89 269,-89 356,-89 356,-89 362,-89 368,-95 368,-101 368,-101 368,-145 368,-145 368,-151 362,-157 356,-157\"/>\r\n<text text-anchor=\"start\" x=\"274\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">pclass ≤ 1.5</text>\r\n<text text-anchor=\"start\" x=\"276\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 0.15</text>\r\n<text text-anchor=\"start\" x=\"265\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 453</text>\r\n<text text-anchor=\"start\" x=\"269.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.183</text>\r\n</g>\r\n<!-- 0&#45;&gt;4 -->\r\n<g id=\"edge4\" class=\"edge\">\r\n<title>0&#45;&gt;4</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M268.78,-192.6C274.06,-184.32 279.78,-175.34 285.3,-166.69\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"288.75,-168.79 291.17,-158.47 282.84,-165.03 288.75,-168.79\"/>\r\n<text text-anchor=\"middle\" x=\"296.58\" y=\"-178.18\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n</g>\r\n<!-- 2 -->\r\n<g id=\"node3\" class=\"node\">\r\n<title>2</title>\r\n<path fill=\"#e58139\" stroke=\"black\" d=\"M99,-53C99,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,0 12,0 12,0 99,0 99,0 105,0 111,-6 111,-12 111,-12 111,-41 111,-41 111,-47 105,-53 99,-53\"/>\r\n<text text-anchor=\"start\" x=\"15\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 0.048</text>\r\n<text text-anchor=\"start\" x=\"8\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 138</text>\r\n<text text-anchor=\"start\" x=\"12.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.949</text>\r\n</g>\r\n<!-- 1&#45;&gt;2 -->\r\n<g id=\"edge2\" class=\"edge\">\r\n<title>1&#45;&gt;2</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M138.37,-88.68C125.62,-79.27 111.78,-69.05 99.12,-59.7\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"101.7,-56.52 91.57,-53.39 97.54,-62.15 101.7,-56.52\"/>\r\n</g>\r\n<!-- 3 -->\r\n<g id=\"node4\" class=\"node\">\r\n<title>3</title>\r\n<path fill=\"#f3c4a2\" stroke=\"black\" d=\"M228,-53C228,-53 141,-53 141,-53 135,-53 129,-47 129,-41 129,-41 129,-12 129,-12 129,-6 135,0 141,0 141,0 228,0 228,0 234,0 240,-6 240,-12 240,-12 240,-41 240,-41 240,-47 234,-53 228,-53\"/>\r\n<text text-anchor=\"start\" x=\"148\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 0.25</text>\r\n<text text-anchor=\"start\" x=\"137\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 120</text>\r\n<text text-anchor=\"start\" x=\"141.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.517</text>\r\n</g>\r\n<!-- 1&#45;&gt;3 -->\r\n<g id=\"edge3\" class=\"edge\">\r\n<title>1&#45;&gt;3</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M183.85,-88.68C183.94,-80.81 184.03,-72.37 184.11,-64.35\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"187.62,-64.43 184.23,-54.39 180.62,-64.36 187.62,-64.43\"/>\r\n</g>\r\n<!-- 5 -->\r\n<g id=\"node6\" class=\"node\">\r\n<title>5</title>\r\n<path fill=\"#f7dac4\" stroke=\"black\" d=\"M351,-53C351,-53 272,-53 272,-53 266,-53 260,-47 260,-41 260,-41 260,-12 260,-12 260,-6 266,0 272,0 272,0 351,0 351,0 357,0 363,-6 363,-12 363,-12 363,-41 363,-41 363,-47 357,-53 351,-53\"/>\r\n<text text-anchor=\"start\" x=\"271\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 0.234</text>\r\n<text text-anchor=\"start\" x=\"268\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 99</text>\r\n<text text-anchor=\"start\" x=\"268.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.374</text>\r\n</g>\r\n<!-- 4&#45;&gt;5 -->\r\n<g id=\"edge5\" class=\"edge\">\r\n<title>4&#45;&gt;5</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M312.15,-88.68C312.06,-80.81 311.97,-72.37 311.89,-64.35\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"315.38,-64.36 311.77,-54.39 308.38,-64.43 315.38,-64.36\"/>\r\n</g>\r\n<!-- 6 -->\r\n<g id=\"node7\" class=\"node\">\r\n<title>6</title>\r\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M480,-53C480,-53 393,-53 393,-53 387,-53 381,-47 381,-41 381,-41 381,-12 381,-12 381,-6 387,0 393,0 393,0 480,0 480,0 486,0 492,-6 492,-12 492,-12 492,-41 492,-41 492,-47 486,-53 480,-53\"/>\r\n<text text-anchor=\"start\" x=\"396\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 0.113</text>\r\n<text text-anchor=\"start\" x=\"389\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 354</text>\r\n<text text-anchor=\"start\" x=\"397.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.13</text>\r\n</g>\r\n<!-- 4&#45;&gt;6 -->\r\n<g id=\"edge6\" class=\"edge\">\r\n<title>4&#45;&gt;6</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M356.22,-88.68C368.45,-79.36 381.72,-69.24 393.89,-59.97\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"395.69,-62.24 401.52,-53.39 391.45,-56.67 395.69,-62.24\"/>\r\n</g>\r\n</g>\r\n</svg>\r\n"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ouqt16nBAglK",
    "colab_type": "text"
   },
   "source": [
    "## RandomForest from scratch. \n",
    "\n",
    "What we need are 2 classes:\n",
    "\n",
    "1. TreeEnsemble class which combines trees.\n",
    "2. DecisionTree class which grows single trees given subsets of data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yed8qqcyXslT",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "start_time": "2023-05-03T13:28:08.531483Z",
     "end_time": "2023-05-03T13:28:08.560624Z"
    }
   },
   "source": [
    "# the TreeEnsemble class is adapted from fastai (the seed has been taken out, comments added, \n",
    "# sample_sz, min_leaf variable name changed, added max_depth parameter\n",
    "class TreeEnsemble():\n",
    "    \"\"\"\n",
    "    A class that builds n estimators (decision trees) and averages their prediction.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, x, y, n_trees, n_samples, min_sample_leaf=5, max_depth=2):\n",
    "        \"\"\"\n",
    "        Initialize the TreeEnsemble\n",
    "        \n",
    "        Args:\n",
    "          x (pandas DataFrame): input data of dimensions (num_instances, num_features)\n",
    "          y (array of targets): numbers for regression or categories for classification\n",
    "          n_trees (int): number of decision trees to create\n",
    "          n_samples (int): number of data samples to use for each tree\n",
    "          min_sample_leaf (int): minimal number of data instances, in order to split the node\n",
    "        \"\"\"\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.n_samples = n_samples \n",
    "        self.min_sample_leaf = min_sample_leaf\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        # create n_trees amout of trees and save them in a list\n",
    "        self.trees = //TODO\n",
    "\n",
    "    def create_tree(self):\n",
    "        # create the indices of data instances to take: 1. permute data indices, 2. take first n_samples\n",
    "        idxs = np.random.permutation(len(self.y))[:self.n_samples]\n",
    "        \n",
    "        return DecisionTree(self.x.iloc[idxs], self.y[idxs], idxs=np.array(range(self.n_samples)), \n",
    "                            min_sample_leaf=self.min_sample_leaf, max_depth=self.max_depth)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        This function calculates the mean prediction over the list of decision trees\n",
    "\n",
    "        Args:\n",
    "          x (pandas DataFrame): input data of dimensions (num_instances, num_features)\n",
    "\n",
    "        Returns:\n",
    "          array of floats of length num_instances: the mean prediction over decision trees for each data instance\n",
    "        \"\"\"\n",
    "        \n",
    "        # given that DecisionTree class also has a predict(x) function, calculate the mean prediction for all trees\n",
    "        # hint: the data (x) has dimensions (num_examples, num_features), so the mean has to be calculated over a specific axis\n",
    "        return //TODO"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avvK31wZRusc",
    "colab_type": "text"
   },
   "source": [
    "Test the TreeEnsemble class with dummy data (only a basic test that the class does not throw errors upon definition)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Q0ht8HJJPb-r",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "start_time": "2023-05-03T13:28:17.324466Z",
     "end_time": "2023-05-03T13:28:17.342475Z"
    }
   },
   "source": [
    "# create a dummy DecisionTree class\n",
    "class DecisionTree():\n",
    "    def __init__(self, x, y, idxs, min_sample_leaf=5, max_depth=2):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, x):\n",
    "      # dummy output\n",
    "      return [1., 2., 3.]"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ItimOK1tR0kE",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "start_time": "2023-05-03T13:28:21.311528Z",
     "end_time": "2023-05-03T13:28:21.374525Z"
    }
   },
   "source": [
    "# test the TreeEnsemble class: the dummy output of DecisionTree suggests 3 data instances, \n",
    "# thus, ens.predict should return the same (think why - how do you calculate the mean?)\n",
    "ens = TreeEnsemble(x_train, y_train, n_trees=5, n_samples=int(0.5*len(x_train)))\n",
    "\n",
    "if not sum(ens.predict(x_train)) == 6:\n",
    "    raise ValueError(\"The tree ensemble implementation does not seem to be correct\")"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6OoHp82tezlL",
    "colab_type": "text"
   },
   "source": [
    "Let us now create the **DecisionTree** class."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_D9GK8c2iNC9",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "start_time": "2023-05-03T13:30:02.070604Z",
     "end_time": "2023-05-03T13:30:02.083604Z"
    }
   },
   "source": [
    "# the DecisionTree class is adapted from fastai \n",
    "# (comments added, variable name (min_leaf) changed, find_varsplit and find_better_split changed)\n",
    "class DecisionTree():\n",
    "    def __init__(self, x, y, idxs, min_sample_leaf=5, max_depth=5, curr_depth=0):\n",
    "        \"\"\"\n",
    "        Initialize the DecisionTree\n",
    "        \n",
    "        Args:\n",
    "          x (pandas DataFrame): input data of dimensions (num_instances, num_features)\n",
    "          y (array of targets): numbers for regression or categories for classification\n",
    "          indxs (array): indices of data instances which belong to this node of the decision tree\n",
    "          min_sample_leaf (int): minimal number of data instances, in order to split the node\n",
    "          max_depth (int): maximum depth of the tree\n",
    "          curr_depth (int): depth of the given node (0 for root, 1 for its children etc.)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.idxs = idxs\n",
    "        self.min_sample_leaf = min_sample_leaf\n",
    "        \n",
    "        # n - number of data instances in the tree/node, c - number of features\n",
    "        self.n,self.c = len(idxs), x.shape[1]\n",
    "        \n",
    "        # the predicted class or regressed value for the leaf\n",
    "        self.val = float(np.mean(y[idxs]))\n",
    "        # the criterion (entropy, mse) value at this node\n",
    "        # it is not identical to the score, \n",
    "        # as the score is the weighting of the criterions of node and children\n",
    "        self.criterion_val = self.split_criterion(y[idxs])\n",
    "        \n",
    "        # the splitting score given the splitting criterion\n",
    "        self.score = float('inf')\n",
    "        self.var_idx = None # index of the feature/variable to split on\n",
    "        self.split = None # the split value\n",
    "        \n",
    "        self.max_depth = max_depth\n",
    "        self.depth = curr_depth\n",
    "                \n",
    "        if self.depth < self.max_depth: self.find_varsplit()\n",
    "        \n",
    "    def find_varsplit(self):\n",
    "        # for each feature, check whether it provides the best split\n",
    "        # set the var_idx, score and split value\n",
    "        for i in range(self.c): \n",
    "            curr_score = self.binary_split(i)\n",
    "            \n",
    "        # the criteria for splitting the node are not met - it will be a leaf\n",
    "        if self.score == float('inf'): return\n",
    "        \n",
    "        # get the values of the column along which the split is about to be done\n",
    "        x = self.split_col\n",
    "        # get the indices of the data instances to the left and right\n",
    "        # numpy.nonzero returns a tuple of arrays, one for each dimension, row-major, C-style\n",
    "        lhs = //TODO\n",
    "        rhs = //TODO\n",
    "        \n",
    "        # create the left and right decision trees, \n",
    "        # pay attentio to select from self.idxs only the correct one\n",
    "        # hint: use lhs and rhs above\n",
    "        self.lhs = DecisionTree(self.x, self.y, //TODO, max_depth=self.max_depth, curr_depth=self.depth+1)\n",
    "        self.rhs = DecisionTree(self.x, self.y, //TODO, max_depth=self.max_depth, curr_depth=self.depth+1)\n",
    "\n",
    "    def binary_split(self, var_idx):\n",
    "        # get the column of all x values for a certain feature\n",
    "        x,y = self.x.values[self.idxs,var_idx], self.y[self.idxs]\n",
    "\n",
    "        # go through all data instances and check whether to split on that value\n",
    "        for i in range(self.n):\n",
    "            # calculate boolean masks which split the feature along a certain value\n",
    "            lhs = //TODO\n",
    "            rhs = //TODO\n",
    "            \n",
    "            # check that both right and left node children have at least min_samples_leaf data instances\n",
    "            # if not - the score will stay infinity, so the node will remain unsplitted\n",
    "            if rhs.sum()<self.min_sample_leaf or lhs.sum()<self.min_sample_leaf: continue\n",
    "            curr_score = self.split_score(lhs, rhs, y)\n",
    "            if curr_score<self.score: \n",
    "                self.var_idx,self.score,self.split = var_idx,curr_score,x[i]\n",
    "\n",
    "    def split_score(self, lhs, rhs, y):\n",
    "        '''\n",
    "        This function calculates the weighted score for the split.\n",
    "        \n",
    "        Args:\n",
    "          lhs (array of booleans): the mask for which instances would split to the left\n",
    "          rhs (array of booleans): the mask for which instances would split to the right\n",
    "          y (array of numbers): the class or value to predict\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        lhs_var = self.split_criterion(y[lhs])\n",
    "        rhs_var = self.split_criterion(y[rhs])\n",
    "        \n",
    "        # weighted (by the number of examples right and left) variance\n",
    "        curr_score = lhs_var*lhs.sum() + rhs_var*rhs.sum()\n",
    "        return curr_score\n",
    "      \n",
    "    def split_criterion(self, y):\n",
    "        # mean squared error is the splitting criterion for regression\n",
    "        # hint: how do mse and variance relate to each other?\n",
    "        return //TODO\n",
    "    \n",
    "    # a property decorator means that you can omit brackets when you call this function\n",
    "    # for example in __repr__ self.split_name\n",
    "    @property\n",
    "    def split_name(self): return self.x.columns[self.var_idx]\n",
    "    \n",
    "    @property\n",
    "    def split_col(self): return self.x.values[self.idxs,self.var_idx]\n",
    "\n",
    "    @property\n",
    "    def is_leaf(self): return self.score == float('inf')\n",
    "    \n",
    "    def __repr__(self):\n",
    "        s = \"n: {0}; val:{1:4f}; mse/entropy/gini:{2:4f}; depth:{3}\".format(self.n, self.val, self.criterion_val, self.depth) \n",
    "        \n",
    "        if not self.is_leaf:\n",
    "            s += \"; score:{0:4f}; split:{1}; var:{2}\".format(self.score,self.split,self.split_name)\n",
    "        return s\n",
    "\n",
    "    def predict(self, x):\n",
    "        # for each data instance (a row of features), make a prediction \n",
    "        return //TODO\n",
    "\n",
    "    def predict_row(self, xi):\n",
    "        if self.is_leaf: return self.val\n",
    "        # check if the feature values for the feature we are splitting on\n",
    "        # are smaller or bigger than the split value\n",
    "        # if smaller/equal - assign left tree to t, else right tree\n",
    "        \n",
    "        t = //TODO\n",
    "        return t.predict_row(xi)"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mySLsiC7j7k0",
    "colab_type": "code",
    "outputId": "a079d6f4-2d9a-4c91-9e80-71867fb43d35",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "ExecuteTime": {
     "start_time": "2023-05-03T13:30:39.594893Z",
     "end_time": "2023-05-03T13:30:40.147891Z"
    }
   },
   "source": [
    "ens = TreeEnsemble(x_train, y_train, 1, len(y_train), max_depth=2)\n",
    "print(ens.trees[0])\n",
    "print(ens.trees[0].lhs)\n",
    "print(ens.trees[0].lhs.lhs)\n",
    "print(ens.trees[0].lhs.rhs)\n",
    "print(ens.trees[0].rhs)"
   ],
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 711; val:0.388186; mse/entropy/gini:0.237498; depth:0; score:116.416525; split:0.0; var:male\n",
      "n: 258; val:0.748062; mse/entropy/gini:0.188465; depth:1; score:36.611594; split:2.0; var:pclass\n",
      "n: 138; val:0.949275; mse/entropy/gini:0.048152; depth:2\n",
      "n: 120; val:0.516667; mse/entropy/gini:0.249722; depth:2\n",
      "n: 453; val:0.183223; mse/entropy/gini:0.149652; depth:1; score:63.194316; split:1.0; var:pclass\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5w0Y_mm3y4Du",
    "colab_type": "code",
    "outputId": "0e26482c-0584-44c9-fcd5-dc4de645c577",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "ExecuteTime": {
     "start_time": "2023-05-03T13:30:44.942573Z",
     "end_time": "2023-05-03T13:30:44.999599Z"
    }
   },
   "source": [
    "# compare the calculated regressed values to the random forest\n",
    "\n",
    "m = RandomForestRegressor(n_estimators=1, max_depth=2, bootstrap=False)\n",
    "m.fit(x_train, y_train)\n",
    "\n",
    "# visualize the fitted tree to your train data\n",
    "dot_data = tree.export_graphviz(m.estimators_[0], out_file=None, \n",
    "                         feature_names=x_train.columns,  \n",
    "                         class_names=labels,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "<graphviz.files.Source at 0x21d80259f10>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Generated by graphviz version 8.0.3 (20230416.2022)\r\n -->\r\n<!-- Title: Tree Pages: 1 -->\r\n<svg width=\"500pt\" height=\"269pt\"\r\n viewBox=\"0.00 0.00 500.00 269.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 265)\">\r\n<title>Tree</title>\r\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-265 496,-265 496,4 -4,4\"/>\r\n<!-- 0 -->\r\n<g id=\"node1\" class=\"node\">\r\n<title>0</title>\r\n<path fill=\"#f7d7c1\" stroke=\"black\" d=\"M291,-261C291,-261 204,-261 204,-261 198,-261 192,-255 192,-249 192,-249 192,-205 192,-205 192,-199 198,-193 204,-193 204,-193 291,-193 291,-193 297,-193 303,-199 303,-205 303,-205 303,-249 303,-249 303,-255 297,-261 291,-261\"/>\r\n<text text-anchor=\"start\" x=\"214\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">male ≤ 0.5</text>\r\n<text text-anchor=\"start\" x=\"207\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 0.237</text>\r\n<text text-anchor=\"start\" x=\"200\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 711</text>\r\n<text text-anchor=\"start\" x=\"204.5\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.388</text>\r\n</g>\r\n<!-- 1 -->\r\n<g id=\"node2\" class=\"node\">\r\n<title>1</title>\r\n<path fill=\"#eba06a\" stroke=\"black\" d=\"M227,-157C227,-157 140,-157 140,-157 134,-157 128,-151 128,-145 128,-145 128,-101 128,-101 128,-95 134,-89 140,-89 140,-89 227,-89 227,-89 233,-89 239,-95 239,-101 239,-101 239,-145 239,-145 239,-151 233,-157 227,-157\"/>\r\n<text text-anchor=\"start\" x=\"145\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">pclass ≤ 2.5</text>\r\n<text text-anchor=\"start\" x=\"143\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 0.188</text>\r\n<text text-anchor=\"start\" x=\"136\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 258</text>\r\n<text text-anchor=\"start\" x=\"140.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.748</text>\r\n</g>\r\n<!-- 0&#45;&gt;1 -->\r\n<g id=\"edge1\" class=\"edge\">\r\n<title>0&#45;&gt;1</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M226.54,-192.6C221.35,-184.32 215.71,-175.34 210.28,-166.69\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"212.78,-165.08 204.5,-158.47 206.85,-168.8 212.78,-165.08\"/>\r\n<text text-anchor=\"middle\" x=\"198.92\" y=\"-178.14\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n</g>\r\n<!-- 4 -->\r\n<g id=\"node5\" class=\"node\">\r\n<title>4</title>\r\n<path fill=\"#fdf7f2\" stroke=\"black\" d=\"M356,-157C356,-157 269,-157 269,-157 263,-157 257,-151 257,-145 257,-145 257,-101 257,-101 257,-95 263,-89 269,-89 269,-89 356,-89 356,-89 362,-89 368,-95 368,-101 368,-101 368,-145 368,-145 368,-151 362,-157 356,-157\"/>\r\n<text text-anchor=\"start\" x=\"274\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">pclass ≤ 1.5</text>\r\n<text text-anchor=\"start\" x=\"276\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 0.15</text>\r\n<text text-anchor=\"start\" x=\"265\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 453</text>\r\n<text text-anchor=\"start\" x=\"269.5\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.183</text>\r\n</g>\r\n<!-- 0&#45;&gt;4 -->\r\n<g id=\"edge4\" class=\"edge\">\r\n<title>0&#45;&gt;4</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M268.78,-192.6C274.06,-184.32 279.78,-175.34 285.3,-166.69\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"288.75,-168.79 291.17,-158.47 282.84,-165.03 288.75,-168.79\"/>\r\n<text text-anchor=\"middle\" x=\"296.58\" y=\"-178.18\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n</g>\r\n<!-- 2 -->\r\n<g id=\"node3\" class=\"node\">\r\n<title>2</title>\r\n<path fill=\"#e58139\" stroke=\"black\" d=\"M99,-53C99,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,0 12,0 12,0 99,0 99,0 105,0 111,-6 111,-12 111,-12 111,-41 111,-41 111,-47 105,-53 99,-53\"/>\r\n<text text-anchor=\"start\" x=\"15\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 0.048</text>\r\n<text text-anchor=\"start\" x=\"8\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 138</text>\r\n<text text-anchor=\"start\" x=\"12.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.949</text>\r\n</g>\r\n<!-- 1&#45;&gt;2 -->\r\n<g id=\"edge2\" class=\"edge\">\r\n<title>1&#45;&gt;2</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M138.37,-88.68C125.62,-79.27 111.78,-69.05 99.12,-59.7\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"101.7,-56.52 91.57,-53.39 97.54,-62.15 101.7,-56.52\"/>\r\n</g>\r\n<!-- 3 -->\r\n<g id=\"node4\" class=\"node\">\r\n<title>3</title>\r\n<path fill=\"#f3c4a2\" stroke=\"black\" d=\"M228,-53C228,-53 141,-53 141,-53 135,-53 129,-47 129,-41 129,-41 129,-12 129,-12 129,-6 135,0 141,0 141,0 228,0 228,0 234,0 240,-6 240,-12 240,-12 240,-41 240,-41 240,-47 234,-53 228,-53\"/>\r\n<text text-anchor=\"start\" x=\"148\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 0.25</text>\r\n<text text-anchor=\"start\" x=\"137\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 120</text>\r\n<text text-anchor=\"start\" x=\"141.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.517</text>\r\n</g>\r\n<!-- 1&#45;&gt;3 -->\r\n<g id=\"edge3\" class=\"edge\">\r\n<title>1&#45;&gt;3</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M183.85,-88.68C183.94,-80.81 184.03,-72.37 184.11,-64.35\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"187.62,-64.43 184.23,-54.39 180.62,-64.36 187.62,-64.43\"/>\r\n</g>\r\n<!-- 5 -->\r\n<g id=\"node6\" class=\"node\">\r\n<title>5</title>\r\n<path fill=\"#f7dac4\" stroke=\"black\" d=\"M351,-53C351,-53 272,-53 272,-53 266,-53 260,-47 260,-41 260,-41 260,-12 260,-12 260,-6 266,0 272,0 272,0 351,0 351,0 357,0 363,-6 363,-12 363,-12 363,-41 363,-41 363,-47 357,-53 351,-53\"/>\r\n<text text-anchor=\"start\" x=\"271\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 0.234</text>\r\n<text text-anchor=\"start\" x=\"268\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 99</text>\r\n<text text-anchor=\"start\" x=\"268.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.374</text>\r\n</g>\r\n<!-- 4&#45;&gt;5 -->\r\n<g id=\"edge5\" class=\"edge\">\r\n<title>4&#45;&gt;5</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M312.15,-88.68C312.06,-80.81 311.97,-72.37 311.89,-64.35\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"315.38,-64.36 311.77,-54.39 308.38,-64.43 315.38,-64.36\"/>\r\n</g>\r\n<!-- 6 -->\r\n<g id=\"node7\" class=\"node\">\r\n<title>6</title>\r\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M480,-53C480,-53 393,-53 393,-53 387,-53 381,-47 381,-41 381,-41 381,-12 381,-12 381,-6 387,0 393,0 393,0 480,0 480,0 486,0 492,-6 492,-12 492,-12 492,-41 492,-41 492,-47 486,-53 480,-53\"/>\r\n<text text-anchor=\"start\" x=\"396\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">mse = 0.113</text>\r\n<text text-anchor=\"start\" x=\"389\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 354</text>\r\n<text text-anchor=\"start\" x=\"397.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = 0.13</text>\r\n</g>\r\n<!-- 4&#45;&gt;6 -->\r\n<g id=\"edge6\" class=\"edge\">\r\n<title>4&#45;&gt;6</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M356.22,-88.68C368.45,-79.36 381.72,-69.24 393.89,-59.97\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"395.69,-62.24 401.52,-53.39 391.45,-56.67 395.69,-62.24\"/>\r\n</g>\r\n</g>\r\n</svg>\r\n"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4767omlEExQ0",
    "colab_type": "text"
   },
   "source": [
    "Exchange the splitting criterion of the DecisionTree from **mse** to** entropy**, create sklearn's **RandomForestClassifier** and compare the entropies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jaKBFoS11RhY",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "start_time": "2023-05-03T13:31:17.790941Z",
     "end_time": "2023-05-03T13:31:17.810966Z"
    }
   },
   "source": [
    "def split_criterion(self, y):\n",
    "    entropy = 0\n",
    "    eps = 1e-15\n",
    "    # yi is the class value, e.g. 0,1,2 if there are 3 classes, 0, 1 in our case\n",
    "    for yi in np.unique(y):\n",
    "        //TODO\n",
    "    return entropy"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wJicDwrl3hL5",
    "colab_type": "code",
    "colab": {},
    "ExecuteTime": {
     "start_time": "2023-05-03T13:31:22.134428Z",
     "end_time": "2023-05-03T13:31:22.161427Z"
    }
   },
   "source": [
    "# exchange the earlier split_criterion function (mse) with the one above\n",
    "DecisionTree.split_criterion=split_criterion"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "10Ja2KEB0VsS",
    "colab_type": "code",
    "outputId": "23d45bf4-24a1-4571-913c-ff344e9a5c22",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "ExecuteTime": {
     "start_time": "2023-05-03T13:31:24.757395Z",
     "end_time": "2023-05-03T13:31:25.396351Z"
    }
   },
   "source": [
    "ens = TreeEnsemble(x_train, y_train, 1, len(y_train), max_depth=2)\n",
    "print(ens.trees[0])\n",
    "print(ens.trees[0].lhs)\n",
    "print(ens.trees[0].lhs.lhs)\n",
    "print(ens.trees[0].lhs.rhs)\n",
    "print(ens.trees[0].rhs)"
   ],
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 711; val:0.388186; mse/entropy/gini:0.963619; depth:0; score:521.344462; split:0.0; var:male\n",
      "n: 258; val:0.748062; mse/entropy/gini:0.814335; depth:1; score:159.850280; split:2.0; var:pclass\n",
      "n: 138; val:0.949275; mse/entropy/gini:0.289467; depth:2\n",
      "n: 120; val:0.516667; mse/entropy/gini:0.999198; depth:2\n",
      "n: 453; val:0.183223; mse/entropy/gini:0.687077; depth:1; score:291.674620; split:1.0; var:pclass\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2uf3AN5a01TF",
    "colab_type": "code",
    "outputId": "ba357aa0-1e0d-4e02-b1ce-c3bbacecd48a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "ExecuteTime": {
     "start_time": "2023-05-03T13:31:26.279420Z",
     "end_time": "2023-05-03T13:31:26.338596Z"
    }
   },
   "source": [
    "# since RandomForestClassifier selects randomly m best features to split on, we fix the seed\n",
    "# the random split on a subset of features serves the aim of reducing overfitting (variance) of the model\n",
    "# for more on bias-variance trade-off check ou:\n",
    "# https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229\n",
    "# if the split is still long different variables than above, then comment the next line out and run the cell a couple of times...\n",
    "np.random.seed(1936483610)\n",
    "\n",
    "m = RandomForestClassifier(n_estimators=1, criterion='entropy', max_depth=2, bootstrap=False)\n",
    "m.fit(x_train, y_train)\n",
    "\n",
    "# visualize the fitted tree to your train data\n",
    "dot_data = tree.export_graphviz(m.estimators_[0], out_file=None, \n",
    "                         feature_names=x_train.columns,  \n",
    "                         class_names=labels,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph"
   ],
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "<graphviz.files.Source at 0x21ddcdaf6a0>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Generated by graphviz version 8.0.3 (20230416.2022)\r\n -->\r\n<!-- Title: Tree Pages: 1 -->\r\n<svg width=\"582pt\" height=\"314pt\"\r\n viewBox=\"0.00 0.00 581.50 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\r\n<title>Tree</title>\r\n<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-310 577.5,-310 577.5,4 -4,4\"/>\r\n<!-- 0 -->\r\n<g id=\"node1\" class=\"node\">\r\n<title>0</title>\r\n<path fill=\"#f5d1b7\" stroke=\"black\" d=\"M327.5,-306C327.5,-306 210.5,-306 210.5,-306 204.5,-306 198.5,-300 198.5,-294 198.5,-294 198.5,-235 198.5,-235 198.5,-229 204.5,-223 210.5,-223 210.5,-223 327.5,-223 327.5,-223 333.5,-223 339.5,-229 339.5,-235 339.5,-235 339.5,-294 339.5,-294 339.5,-300 333.5,-306 327.5,-306\"/>\r\n<text text-anchor=\"start\" x=\"235.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">male ≤ 0.5</text>\r\n<text text-anchor=\"start\" x=\"219\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.964</text>\r\n<text text-anchor=\"start\" x=\"221.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 711</text>\r\n<text text-anchor=\"start\" x=\"212\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [435, 276]</text>\r\n<text text-anchor=\"start\" x=\"206.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = not survived</text>\r\n</g>\r\n<!-- 1 -->\r\n<g id=\"node2\" class=\"node\">\r\n<title>1</title>\r\n<path fill=\"#7cbeee\" stroke=\"black\" d=\"M243,-187C243,-187 145,-187 145,-187 139,-187 133,-181 133,-175 133,-175 133,-116 133,-116 133,-110 139,-104 145,-104 145,-104 243,-104 243,-104 249,-104 255,-110 255,-116 255,-116 255,-175 255,-175 255,-181 249,-187 243,-187\"/>\r\n<text text-anchor=\"start\" x=\"155.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">pclass ≤ 2.5</text>\r\n<text text-anchor=\"start\" x=\"144\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.814</text>\r\n<text text-anchor=\"start\" x=\"146.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 258</text>\r\n<text text-anchor=\"start\" x=\"141\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [65, 193]</text>\r\n<text text-anchor=\"start\" x=\"143\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = survived</text>\r\n</g>\r\n<!-- 0&#45;&gt;1 -->\r\n<g id=\"edge1\" class=\"edge\">\r\n<title>0&#45;&gt;1</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M242.77,-222.58C237.31,-214.07 231.51,-205.01 225.88,-196.23\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"228.43,-194.73 220.09,-188.2 222.54,-198.51 228.43,-194.73\"/>\r\n<text text-anchor=\"middle\" x=\"214.75\" y=\"-207.92\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n</g>\r\n<!-- 4 -->\r\n<g id=\"node5\" class=\"node\">\r\n<title>4</title>\r\n<path fill=\"#eb9d65\" stroke=\"black\" d=\"M402.5,-187C402.5,-187 285.5,-187 285.5,-187 279.5,-187 273.5,-181 273.5,-175 273.5,-175 273.5,-116 273.5,-116 273.5,-110 279.5,-104 285.5,-104 285.5,-104 402.5,-104 402.5,-104 408.5,-104 414.5,-110 414.5,-116 414.5,-116 414.5,-175 414.5,-175 414.5,-181 408.5,-187 402.5,-187\"/>\r\n<text text-anchor=\"start\" x=\"301.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">fare ≤ 26.269</text>\r\n<text text-anchor=\"start\" x=\"294\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.687</text>\r\n<text text-anchor=\"start\" x=\"296.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 453</text>\r\n<text text-anchor=\"start\" x=\"291\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [370, 83]</text>\r\n<text text-anchor=\"start\" x=\"281.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = not survived</text>\r\n</g>\r\n<!-- 0&#45;&gt;4 -->\r\n<g id=\"edge4\" class=\"edge\">\r\n<title>0&#45;&gt;4</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M295.23,-222.58C300.69,-214.07 306.49,-205.01 312.12,-196.23\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"315.46,-198.51 317.91,-188.2 309.57,-194.73 315.46,-198.51\"/>\r\n<text text-anchor=\"middle\" x=\"323.25\" y=\"-207.92\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n</g>\r\n<!-- 2 -->\r\n<g id=\"node3\" class=\"node\">\r\n<title>2</title>\r\n<path fill=\"#44a2e6\" stroke=\"black\" d=\"M106,-68C106,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 106,0 106,0 112,0 118,-6 118,-12 118,-12 118,-56 118,-56 118,-62 112,-68 106,-68\"/>\r\n<text text-anchor=\"start\" x=\"9\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.289</text>\r\n<text text-anchor=\"start\" x=\"11.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 138</text>\r\n<text text-anchor=\"start\" x=\"10.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 131]</text>\r\n<text text-anchor=\"start\" x=\"8\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = survived</text>\r\n</g>\r\n<!-- 1&#45;&gt;2 -->\r\n<g id=\"edge2\" class=\"edge\">\r\n<title>1&#45;&gt;2</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M143.73,-103.73C132.15,-94.33 119.84,-84.35 108.3,-74.99\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"111.03,-71.88 101.05,-68.3 106.62,-77.32 111.03,-71.88\"/>\r\n</g>\r\n<!-- 3 -->\r\n<g id=\"node4\" class=\"node\">\r\n<title>3</title>\r\n<path fill=\"#f2f9fd\" stroke=\"black\" d=\"M242,-68C242,-68 148,-68 148,-68 142,-68 136,-62 136,-56 136,-56 136,-12 136,-12 136,-6 142,0 148,0 148,0 242,0 242,0 248,0 254,-6 254,-12 254,-12 254,-56 254,-56 254,-62 248,-68 242,-68\"/>\r\n<text text-anchor=\"start\" x=\"145\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.999</text>\r\n<text text-anchor=\"start\" x=\"147.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 120</text>\r\n<text text-anchor=\"start\" x=\"146.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [58, 62]</text>\r\n<text text-anchor=\"start\" x=\"144\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = survived</text>\r\n</g>\r\n<!-- 1&#45;&gt;3 -->\r\n<g id=\"edge3\" class=\"edge\">\r\n<title>1&#45;&gt;3</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M194.37,-103.73C194.45,-95.7 194.52,-87.24 194.6,-79.11\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"198.1,-79.33 194.7,-69.3 191.1,-79.27 198.1,-79.33\"/>\r\n</g>\r\n<!-- 5 -->\r\n<g id=\"node6\" class=\"node\">\r\n<title>5</title>\r\n<path fill=\"#e99356\" stroke=\"black\" d=\"M402.5,-68C402.5,-68 285.5,-68 285.5,-68 279.5,-68 273.5,-62 273.5,-56 273.5,-56 273.5,-12 273.5,-12 273.5,-6 279.5,0 285.5,0 285.5,0 402.5,0 402.5,0 408.5,0 414.5,-6 414.5,-12 414.5,-12 414.5,-56 414.5,-56 414.5,-62 408.5,-68 402.5,-68\"/>\r\n<text text-anchor=\"start\" x=\"294\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.547</text>\r\n<text text-anchor=\"start\" x=\"296.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 325</text>\r\n<text text-anchor=\"start\" x=\"291\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [284, 41]</text>\r\n<text text-anchor=\"start\" x=\"281.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = not survived</text>\r\n</g>\r\n<!-- 4&#45;&gt;5 -->\r\n<g id=\"edge5\" class=\"edge\">\r\n<title>4&#45;&gt;5</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M344,-103.73C344,-95.7 344,-87.24 344,-79.11\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"347.5,-79.3 344,-69.3 340.5,-79.3 347.5,-79.3\"/>\r\n</g>\r\n<!-- 6 -->\r\n<g id=\"node7\" class=\"node\">\r\n<title>6</title>\r\n<path fill=\"#f2bf9a\" stroke=\"black\" d=\"M561.5,-68C561.5,-68 444.5,-68 444.5,-68 438.5,-68 432.5,-62 432.5,-56 432.5,-56 432.5,-12 432.5,-12 432.5,-6 438.5,0 444.5,0 444.5,0 561.5,0 561.5,0 567.5,0 573.5,-6 573.5,-12 573.5,-12 573.5,-56 573.5,-56 573.5,-62 567.5,-68 561.5,-68\"/>\r\n<text text-anchor=\"start\" x=\"453\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.913</text>\r\n<text text-anchor=\"start\" x=\"455.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 128</text>\r\n<text text-anchor=\"start\" x=\"454.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [86, 42]</text>\r\n<text text-anchor=\"start\" x=\"440.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = not survived</text>\r\n</g>\r\n<!-- 4&#45;&gt;6 -->\r\n<g id=\"edge6\" class=\"edge\">\r\n<title>4&#45;&gt;6</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M403.21,-103.73C417.04,-94.2 431.75,-84.07 445.51,-74.59\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"447.14,-77.03 453.39,-68.47 443.17,-71.26 447.14,-77.03\"/>\r\n</g>\r\n</g>\r\n</svg>\r\n"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HV8XZ4YghlIG",
    "colab_type": "code",
    "colab": {}
   },
   "source": [],
   "execution_count": 0,
   "outputs": []
  }
 ]
}
